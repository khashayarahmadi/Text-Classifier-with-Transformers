{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8365347,"sourceType":"datasetVersion","datasetId":4972386}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/khashayarahmadi/an-advanced-text-classifier-with-99-accuracy?scriptVersionId=176625458\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Text classification with Transformers\n","metadata":{}},{"cell_type":"code","source":"!pip install transformers\n!pip install datasets\n!pip install --upgrade pandas\n!pip install evaluate\n!pip install accelerate -U","metadata":{"execution":{"iopub.status.busy":"2024-05-09T11:05:48.457085Z","iopub.execute_input":"2024-05-09T11:05:48.457565Z","iopub.status.idle":"2024-05-09T11:07:08.117623Z","shell.execute_reply.started":"2024-05-09T11:05:48.457537Z","shell.execute_reply":"2024-05-09T11:07:08.116649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# #CONFIG","metadata":{}},{"cell_type":"code","source":"data_path = \"/kaggle/input/email-spam/dataset.csv\" \ntext_column_name = \"email\" \nlabel_column_name = \"category\" \n\nmodel_name = \"distilbert-base-uncased\" \ntest_size = 0.2 \nnum_labels = 2 ","metadata":{"execution":{"iopub.status.busy":"2024-05-09T11:11:18.927891Z","iopub.execute_input":"2024-05-09T11:11:18.928568Z","iopub.status.idle":"2024-05-09T11:11:18.93396Z","shell.execute_reply.started":"2024-05-09T11:11:18.928526Z","shell.execute_reply":"2024-05-09T11:11:18.932853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Importing libraries ","metadata":{}},{"cell_type":"code","source":"\nimport evaluate\nimport numpy as np\nimport pandas as pd\nfrom bs4 import BeautifulSoup\nfrom datasets import Dataset\nfrom sklearn.metrics import classification_report\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom transformers import AutoTokenizer\nfrom transformers import AutoModelForSequenceClassification\nfrom transformers import DataCollatorWithPadding\nfrom transformers import TrainingArguments, Trainer\n","metadata":{"execution":{"iopub.status.busy":"2024-05-09T11:13:23.509937Z","iopub.execute_input":"2024-05-09T11:13:23.510655Z","iopub.status.idle":"2024-05-09T11:13:23.519372Z","shell.execute_reply.started":"2024-05-09T11:13:23.510623Z","shell.execute_reply":"2024-05-09T11:13:23.518372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Importing data set ","metadata":{}},{"cell_type":"markdown","source":"our data set contain two section email with whole body and the category for showing the lable of the email","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(data_path)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-09T11:13:47.471454Z","iopub.execute_input":"2024-05-09T11:13:47.472223Z","iopub.status.idle":"2024-05-09T11:13:47.726191Z","shell.execute_reply.started":"2024-05-09T11:13:47.472184Z","shell.execute_reply":"2024-05-09T11:13:47.725255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Makeing a class for cleaning data with BeautifulSoup","metadata":{}},{"cell_type":"code","source":"\nclass Cleaner():\n  def __init__(self):\n    pass\n  def put_line_breaks(self,text):\n    text = text.replace('</p>','</p>\\n')\n    return text\n  def remove_html_tags(self,text):\n    cleantext = BeautifulSoup(text, \"lxml\").text\n    return cleantext\n  def clean(self,text):\n    text = self.put_line_breaks(text)\n    text = self.remove_html_tags(text)\n    return text","metadata":{"execution":{"iopub.status.busy":"2024-05-09T11:17:21.126729Z","iopub.execute_input":"2024-05-09T11:17:21.127331Z","iopub.status.idle":"2024-05-09T11:17:21.133268Z","shell.execute_reply.started":"2024-05-09T11:17:21.127287Z","shell.execute_reply":"2024-05-09T11:17:21.13233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cleaner = Cleaner()\ndf['text_cleaned'] = df[text_column_name].apply(cleaner.clean)","metadata":{"execution":{"iopub.status.busy":"2024-05-09T11:18:18.122966Z","iopub.execute_input":"2024-05-09T11:18:18.123319Z","iopub.status.idle":"2024-05-09T11:18:22.591238Z","shell.execute_reply.started":"2024-05-09T11:18:18.123279Z","shell.execute_reply":"2024-05-09T11:18:22.590463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-09T11:18:42.98858Z","iopub.execute_input":"2024-05-09T11:18:42.989386Z","iopub.status.idle":"2024-05-09T11:18:43.004185Z","shell.execute_reply.started":"2024-05-09T11:18:42.98935Z","shell.execute_reply":"2024-05-09T11:18:43.002708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We have a new column with cleaned text which we will use\nas follows i use lable encoder for encoding the category column","metadata":{}},{"cell_type":"code","source":"le = preprocessing.LabelEncoder()\nle.fit(df[label_column_name].tolist())\ndf['label'] = le.transform(df[label_column_name].tolist())","metadata":{"execution":{"iopub.status.busy":"2024-05-09T11:22:28.092493Z","iopub.execute_input":"2024-05-09T11:22:28.092831Z","iopub.status.idle":"2024-05-09T11:22:28.103787Z","shell.execute_reply.started":"2024-05-09T11:22:28.092805Z","shell.execute_reply":"2024-05-09T11:22:28.102947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-09T11:22:39.238194Z","iopub.execute_input":"2024-05-09T11:22:39.238553Z","iopub.status.idle":"2024-05-09T11:22:39.251512Z","shell.execute_reply.started":"2024-05-09T11:22:39.238524Z","shell.execute_reply":"2024-05-09T11:22:39.250641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train,df_test = train_test_split(df,test_size=test_size)","metadata":{"execution":{"iopub.status.busy":"2024-05-09T11:23:13.022243Z","iopub.execute_input":"2024-05-09T11:23:13.022922Z","iopub.status.idle":"2024-05-09T11:23:13.038154Z","shell.execute_reply.started":"2024-05-09T11:23:13.022887Z","shell.execute_reply":"2024-05-09T11:23:13.037116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = Dataset.from_pandas(df_train)\ntest_dataset = Dataset.from_pandas(df_test)","metadata":{"execution":{"iopub.status.busy":"2024-05-09T11:23:23.961845Z","iopub.execute_input":"2024-05-09T11:23:23.962627Z","iopub.status.idle":"2024-05-09T11:23:24.188419Z","shell.execute_reply.started":"2024-05-09T11:23:23.962595Z","shell.execute_reply":"2024-05-09T11:23:24.187629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# we use AutoTokenizer for tokenizing the cleaned text ","metadata":{}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_name)\n\ndef preprocess_function(examples):\n    return tokenizer(examples[\"text_cleaned\"], truncation=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-09T11:23:40.604216Z","iopub.execute_input":"2024-05-09T11:23:40.60462Z","iopub.status.idle":"2024-05-09T11:23:41.404649Z","shell.execute_reply.started":"2024-05-09T11:23:40.604589Z","shell.execute_reply":"2024-05-09T11:23:41.403873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# make two parts for our model training : Test and Train","metadata":{}},{"cell_type":"code","source":"tokenized_train = train_dataset.map(preprocess_function, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-09T11:24:44.942153Z","iopub.execute_input":"2024-05-09T11:24:44.942753Z","iopub.status.idle":"2024-05-09T11:24:50.587488Z","shell.execute_reply.started":"2024-05-09T11:24:44.942719Z","shell.execute_reply":"2024-05-09T11:24:50.586634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_test = test_dataset.map(preprocess_function, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-09T11:24:53.060016Z","iopub.execute_input":"2024-05-09T11:24:53.060421Z","iopub.status.idle":"2024-05-09T11:24:53.885204Z","shell.execute_reply.started":"2024-05-09T11:24:53.06039Z","shell.execute_reply":"2024-05-09T11:24:53.884351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Initialize Model","metadata":{}},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)","metadata":{"execution":{"iopub.status.busy":"2024-05-09T11:26:00.641901Z","iopub.execute_input":"2024-05-09T11:26:00.642533Z","iopub.status.idle":"2024-05-09T11:26:02.238714Z","shell.execute_reply.started":"2024-05-09T11:26:00.642503Z","shell.execute_reply":"2024-05-09T11:26:02.237743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train model","metadata":{}},{"cell_type":"code","source":"data_collator = DataCollatorWithPadding(tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-05-09T11:26:20.041354Z","iopub.execute_input":"2024-05-09T11:26:20.041716Z","iopub.status.idle":"2024-05-09T11:26:20.046233Z","shell.execute_reply.started":"2024-05-09T11:26:20.041685Z","shell.execute_reply":"2024-05-09T11:26:20.0452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metric = evaluate.load(\"accuracy\")\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=-1)\n    return metric.compute(predictions=predictions, references=labels)","metadata":{"execution":{"iopub.status.busy":"2024-05-09T11:26:29.154755Z","iopub.execute_input":"2024-05-09T11:26:29.155111Z","iopub.status.idle":"2024-05-09T11:26:29.641899Z","shell.execute_reply.started":"2024-05-09T11:26:29.155082Z","shell.execute_reply":"2024-05-09T11:26:29.641151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"./results\",\n    learning_rate=2e-4,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    num_train_epochs=5,\n    weight_decay=0.01,\n    evaluation_strategy = \"epoch\",\n    logging_strategy=\"epoch\"\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_train,\n    eval_dataset=tokenized_test,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics\n    \n)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-09T11:27:41.833247Z","iopub.execute_input":"2024-05-09T11:27:41.833647Z","iopub.status.idle":"2024-05-09T11:27:42.954918Z","shell.execute_reply.started":"2024-05-09T11:27:41.833615Z","shell.execute_reply":"2024-05-09T11:27:42.953964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-05-09T11:27:55.876629Z","iopub.execute_input":"2024-05-09T11:27:55.876985Z","iopub.status.idle":"2024-05-09T11:39:19.750809Z","shell.execute_reply.started":"2024-05-09T11:27:55.876956Z","shell.execute_reply":"2024-05-09T11:39:19.749379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.save_model('spam_model')","metadata":{"execution":{"iopub.status.busy":"2024-05-09T11:40:39.431518Z","iopub.execute_input":"2024-05-09T11:40:39.432245Z","iopub.status.idle":"2024-05-09T11:40:39.990835Z","shell.execute_reply.started":"2024-05-09T11:40:39.432214Z","shell.execute_reply":"2024-05-09T11:40:39.989776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#  Evaluate Model","metadata":{}},{"cell_type":"code","source":"preds = trainer.predict(tokenized_train)\npreds = np.argmax(preds[:3][0],axis=1)\nGT = df_train['label'].tolist()\nprint(classification_report(GT,preds))","metadata":{"execution":{"iopub.status.busy":"2024-05-09T11:41:10.03243Z","iopub.execute_input":"2024-05-09T11:41:10.032777Z","iopub.status.idle":"2024-05-09T11:41:40.914856Z","shell.execute_reply.started":"2024-05-09T11:41:10.032752Z","shell.execute_reply":"2024-05-09T11:41:40.913907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = trainer.predict(tokenized_test)\npreds = np.argmax(preds[:3][0],axis=1) #preds[:3][1]\nGT = df_test['label'].tolist()\nprint(classification_report(GT,preds))","metadata":{"execution":{"iopub.status.busy":"2024-05-09T11:41:44.011072Z","iopub.execute_input":"2024-05-09T11:41:44.011968Z","iopub.status.idle":"2024-05-09T11:41:51.52685Z","shell.execute_reply.started":"2024-05-09T11:41:44.011936Z","shell.execute_reply":"2024-05-09T11:41:51.525786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Resualt is awsome we have have 99% accuracy","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}}]}